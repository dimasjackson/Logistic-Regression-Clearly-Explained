{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dimasjackson/logistic-regression-clearly-explained?scriptVersionId=116899036\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"08b6fe8c","metadata":{"papermill":{"duration":0.007836,"end_time":"2023-01-20T20:37:18.275619","exception":false,"start_time":"2023-01-20T20:37:18.267783","status":"completed"},"tags":[]},"source":["# Logistic Regression\n","\n","Logístic Regression is a statistical model that is used in classification and predictive analysis. This model is also know as Logit and it is characterized by a single binary dependent variable, i. e. a variable that only can take two values, often labeled as 0 and 1. Binary values are widely udsed in statistics to model the probablity of a certain event occuring, such as the probability of a pacient being health, a tumor being malignant or not, if an email is spam or not and if a team win or loose. Therefore, Logistic Regression has a large variety of applications. \n","\n","The logistic function is defined by:\n","$$ p(x) = \\dfrac{1}{1+e^{-(x-\\mu)/s}} $$\n","where $\\mu$ is the midpoint of the curve ($p(\\mu)=1/2$) and $s$ a scale parameter that determines the spread of the probability distribution. This function is also called **sigmoid function**, because of its 's' shape.\n","\n","The logistic fuction is used to generate predictions as we will see below. Furthermore, it is interesting to write this function as \n","$$ p(x) = \\dfrac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}} \\,,$$ \n","where $\\beta_0 = -\\mu/s$ is the intercept of the line $y = \\beta_0 + \\beta_1 x$ and $\\beta_1 = 1/s$ is its slope. The parameter $\\beta_0$ is also called \"bias\" and $\\beta_1$ \"weights\". The particular values of these quantities that maximizes the likelyhood function are what we need to find to make predictions."]},{"cell_type":"code","execution_count":1,"id":"49339e6d","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.291673Z","iopub.status.busy":"2023-01-20T20:37:18.291141Z","iopub.status.idle":"2023-01-20T20:37:18.30292Z","shell.execute_reply":"2023-01-20T20:37:18.301875Z"},"papermill":{"duration":0.022263,"end_time":"2023-01-20T20:37:18.304834","exception":false,"start_time":"2023-01-20T20:37:18.282571","status":"completed"},"tags":[]},"outputs":[],"source":["# Defining the sigmoid function\n","\n","import numpy as np # Importing a linear algebra package\n","import matplotlib.pyplot as plt # To plot figures\n","\n","def sigmoid(beta_1, beta_0, x):\n","    return 1/(1+np.exp(-(beta_1*x-beta_0)))"]},{"cell_type":"code","execution_count":2,"id":"61dee0e7","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.321469Z","iopub.status.busy":"2023-01-20T20:37:18.320534Z","iopub.status.idle":"2023-01-20T20:37:18.505439Z","shell.execute_reply":"2023-01-20T20:37:18.503951Z"},"papermill":{"duration":0.195807,"end_time":"2023-01-20T20:37:18.507722","exception":false,"start_time":"2023-01-20T20:37:18.311915","status":"completed"},"tags":[]},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["x = np.linspace(-10,10,10000) # Defining a interval\n","y = sigmoid(1,0,x) # Defining the dependent variable\n","plt.plot(x, y)\n","plt.title(\"Sigmoid: the probability distribution of logistic model\")\n","plt.xlabel(xlabel=\"x\")\n","plt.ylabel(ylabel=\"p(x)\")\n","plt.show()\n"]},{"cell_type":"markdown","id":"62f94420","metadata":{"papermill":{"duration":0.006854,"end_time":"2023-01-20T20:37:18.521946","exception":false,"start_time":"2023-01-20T20:37:18.515092","status":"completed"},"tags":[]},"source":["# Types of Logistic Regression\n","\n","1. Binary Logistic Regression\n","\n","The categorical response has only two 2 possible outcomes. Example: Spam or Not.\n","\n","2. Multinomial Logistic Regression\n","\n","Three or more categories without ordering. Example: Predicting which food is preferred more (Veg, Non-Veg, Vegan).\n","\n","3. Ordinal Logistic Regression\n","\n","Three or more categories with ordering. Example: Movie rating from 1 to 5."]},{"cell_type":"markdown","id":"cfaa62e0","metadata":{"papermill":{"duration":0.006689,"end_time":"2023-01-20T20:37:18.535557","exception":false,"start_time":"2023-01-20T20:37:18.528868","status":"completed"},"tags":[]},"source":["# Example\n","\n","The logistic regression can be used with one **explanatory variable** and two **categories** to answer a question. As an example, consider the case of a group of students which are preparing for a exam. The question is: how does the number of study hours affect the probability of the student passing the exam? In this case the explanatory variable is the number of hours studying and the two categories are being approved or not. Let's consider 10 students that spends between 0 to 10 hours studing and use 1 to identify \"pass\" and 0 to \"fail\". Then, we have the following \"sintetic\" data:"]},{"cell_type":"code","execution_count":3,"id":"7b688ff5","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.552345Z","iopub.status.busy":"2023-01-20T20:37:18.55199Z","iopub.status.idle":"2023-01-20T20:37:18.574797Z","shell.execute_reply":"2023-01-20T20:37:18.573241Z"},"papermill":{"duration":0.034826,"end_time":"2023-01-20T20:37:18.57731","exception":false,"start_time":"2023-01-20T20:37:18.542484","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Hours</th>\n","      <th>Pass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Hours  Pass\n","0    0.0     0\n","1    1.0     0\n","2    2.5     0\n","3    4.0     0\n","4    4.0     1\n","5    4.5     0\n","6    5.0     1\n","7    6.0     1\n","8    8.0     1\n","9   10.0     1"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd # Data set management\n","\n","df = pd.DataFrame(data={\"Hours\":[0,1,2.5,4,4,4.5,5,6,8,10],\"Pass\":[0,0,0,0,1,0,1,1,1,1]})\n","df"]},{"cell_type":"markdown","id":"8f1f037b","metadata":{"papermill":{"duration":0.006964,"end_time":"2023-01-20T20:37:18.591629","exception":false,"start_time":"2023-01-20T20:37:18.584665","status":"completed"},"tags":[]},"source":["To predict if a student will pass or not we need to consider the loss function, which is a function that represents the \"price to pay\" for inaccuracy of predictions. Usually, the logistic loss function is used as the measure of goodness of a fit in logistic regression. Considering that $p_k$ is the probability that the $k-$th student will pass the exam and $1-p_k$ the fail probability, the log loss for the $k-$th point is:\n","$$ \\begin{cases}\n","-\\ln p_{k} & \\text{if }y_{k}=1\\\\\n","-\\ln(1-p_{k}) & \\text{if }y_{k}=0\n","\\end{cases} $$\n","\n","Note that log loss is always greater than or equal to 0, equals 0 only in case of a perfect prediction, and approaches to infinity when predictions get worse. The two cases can be combined into a function called cross entropy:\n","$$ -y_k \\ln p_k -(1-y_k) \\ln (1-p_k) $$\n","\n","The sum of the this term for all elements is the negative likelihood function:\n","$$ -l = -\\sum_k^N [y_k \\ln p_k +(1-y_k) \\ln (1-p_k)]$$\n","\n","To estimate the probability of an outcome we need to find the values of $\\beta_0$ and $\\beta_1$ that minimizes the negative likelihood (or maximizes the positive likelihood, if you prefer). This is accomplished taking the derivative of the likelihood with respect to these parameters (or applying the gradient operator in high dimension problems):\n","$$ 0 = \\frac{\\partial l}{\\partial \\beta_0} = \\sum_{k=1}^N(y_k-p_k) $$\n","$$ 0 = \\frac{\\partial l}{\\partial \\beta_1} = \\sum_{k=1}^N(y_k-p_k)x_k $$\n","Then we need to solve the above two equations for  $\\beta_{0}$ and $\\beta_{1}$, which generally requires the use of numerical methods. For example, we may start with $\\beta_0 = 0$ and $ \\beta_1 = 0$ and iterate the model increasing these parameters by a fraction of the gradient. After that, the probability of passing or failing the exam can be calculated using the sigmoid function\n","$$ p = \\dfrac{1}{1+e^{-t}}\\,,$$\n","where $t = \\beta_0 + x\\beta_1$. Let's implement this calculation using python functions\n","\n"]},{"cell_type":"markdown","id":"625aba00","metadata":{"papermill":{"duration":0.006899,"end_time":"2023-01-20T20:37:18.605663","exception":false,"start_time":"2023-01-20T20:37:18.598764","status":"completed"},"tags":[]},"source":["# Our Implementation"]},{"cell_type":"markdown","id":"8fb16c7b","metadata":{"papermill":{"duration":0.006885,"end_time":"2023-01-20T20:37:18.619572","exception":false,"start_time":"2023-01-20T20:37:18.612687","status":"completed"},"tags":[]},"source":[" We will start with $\\beta_0 = 0$ and $ \\beta_1 = 0.01(1,1,\\dots,1)$ and iterate the model increasing these parameters by a fraction of the gradient. This fraction amount is usually called \"learning rate\"."]},{"cell_type":"code","execution_count":4,"id":"7eee6445","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.636457Z","iopub.status.busy":"2023-01-20T20:37:18.636048Z","iopub.status.idle":"2023-01-20T20:37:18.641989Z","shell.execute_reply":"2023-01-20T20:37:18.640481Z"},"papermill":{"duration":0.017547,"end_time":"2023-01-20T20:37:18.644428","exception":false,"start_time":"2023-01-20T20:37:18.626881","status":"completed"},"tags":[]},"outputs":[],"source":["# Defining the initial parameters (zeros)\n","def weightInitialization(n_features):\n","    beta_1 = np.full((n_features),0.01) # Note that beta_1 must have the same dimension of x\n","    beta_0 = 0\n","    return beta_1,beta_0"]},{"cell_type":"code","execution_count":5,"id":"ee458700","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.661653Z","iopub.status.busy":"2023-01-20T20:37:18.661291Z","iopub.status.idle":"2023-01-20T20:37:18.667396Z","shell.execute_reply":"2023-01-20T20:37:18.665872Z"},"papermill":{"duration":0.017253,"end_time":"2023-01-20T20:37:18.669632","exception":false,"start_time":"2023-01-20T20:37:18.652379","status":"completed"},"tags":[]},"outputs":[],"source":["# Defining the sigmoid function\n","def sigmoid_vec(t):\n","    p = 1/(1+np.exp(-t)) # The .T means the transpose of x and np.dot the dot product\n","    return p[0]"]},{"cell_type":"code","execution_count":6,"id":"716d1cba","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.686763Z","iopub.status.busy":"2023-01-20T20:37:18.686386Z","iopub.status.idle":"2023-01-20T20:37:18.693906Z","shell.execute_reply":"2023-01-20T20:37:18.692359Z"},"papermill":{"duration":0.01962,"end_time":"2023-01-20T20:37:18.696633","exception":false,"start_time":"2023-01-20T20:37:18.677013","status":"completed"},"tags":[]},"outputs":[],"source":["# Calculates the likelihood and the derivatives\n","def log_model(beta_1, beta_0, x, y):\n","       \n","    #Prediction\n","    t = np.dot(beta_1, x.T) + beta_0\n","    prob = sigmoid_vec(t)\n","    y = np.array(y)\n","    likelihood = np.sum( -y*np.log(prob) - (1 - y)*np.log(1 - prob) )/x.shape[1] # The factor 1/x.shape[1] is for scaling by the n# of features\n","    \n","    #Gradient calculation\n","    dbeta_1 = np.dot(x.T, (prob-y))/x.shape[1]\n","    dbeta_0 = np.sum(prob-y)/x.shape[1]\n","    \n","    gradients = {\"dbeta_1\": dbeta_1, \"dbeta_0\": dbeta_0}\n","    \n","    return gradients, likelihood "]},{"cell_type":"code","execution_count":7,"id":"3f8bd41e","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.713217Z","iopub.status.busy":"2023-01-20T20:37:18.712833Z","iopub.status.idle":"2023-01-20T20:37:18.72048Z","shell.execute_reply":"2023-01-20T20:37:18.719191Z"},"papermill":{"duration":0.018311,"end_time":"2023-01-20T20:37:18.722499","exception":false,"start_time":"2023-01-20T20:37:18.704188","status":"completed"},"tags":[]},"outputs":[],"source":["# Iterate the model to make it learn\n","def model_predict(n_features, x, y, learning_rate, n_iterations):\n","    beta_1, beta_0 = weightInitialization(n_features)\n","    costs = []\n","    for i in range(n_iterations):\n","        \n","        gradients, likelihood = log_model(beta_1, beta_0, x, y)\n","        \n","        dbeta_1 = gradients[\"dbeta_1\"]\n","        dbeta_0 = gradients[\"dbeta_0\"]\n","        #weight update\n","        beta_1 = beta_1 - (learning_rate * dbeta_1)\n","        beta_0 = beta_0 - (learning_rate * dbeta_0)\n","        costs.append(likelihood)\n","            \n","    #final parameters\n","    parameters = {\"beta_1\": beta_1, \"beta_0\": beta_0}\n","    gradient = {\"dbeta_1\": dbeta_1, \"dbeta_0\": dbeta_0}\n","        \n","    return parameters, gradient, costs"]},{"cell_type":"code","execution_count":8,"id":"8b9f57e6","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.739221Z","iopub.status.busy":"2023-01-20T20:37:18.738813Z","iopub.status.idle":"2023-01-20T20:37:18.746902Z","shell.execute_reply":"2023-01-20T20:37:18.745012Z"},"papermill":{"duration":0.019236,"end_time":"2023-01-20T20:37:18.749339","exception":false,"start_time":"2023-01-20T20:37:18.730103","status":"completed"},"tags":[]},"outputs":[],"source":["# Create an array with the final predictions\n","# Given a bias beta_0, a weight beta_1 and a input x return the predicted probability of pass or fail\n","def predict(beta_1, beta_0, x): \n","    t = np.dot(beta_1, x.T) + beta_0\n","    z = sigmoid_vec(t)\n","    y_pred = np.zeros(x.shape[0])\n","    for i in range(y_pred.shape[0]):\n","        if z > 0.5:\n","            y_pred[i] = 1\n","    return y_pred"]},{"cell_type":"code","execution_count":9,"id":"db84df32","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.767424Z","iopub.status.busy":"2023-01-20T20:37:18.767045Z","iopub.status.idle":"2023-01-20T20:37:18.773146Z","shell.execute_reply":"2023-01-20T20:37:18.771784Z"},"papermill":{"duration":0.018035,"end_time":"2023-01-20T20:37:18.775457","exception":false,"start_time":"2023-01-20T20:37:18.757422","status":"completed"},"tags":[]},"outputs":[],"source":["# Defining our logistic regression model\n","def my_Logistic_Regression(x_train, y_train, x_test, learning_rate, n_iterations):\n","    n_features = x_train.shape[1] # Dimension of the input\n","    beta_1, beta_0 = weightInitialization(n_features) # Defined above\n","    parameters, gradients, costs = model_predict(n_features, x_train, y_train, learning_rate, n_iterations)# Defined above\n","    y_pred = predict(parameters[\"beta_1\"], parameters[\"beta_0\"], x_test) # Defined above\n","    return y_pred"]},{"cell_type":"markdown","id":"7d89b886","metadata":{"papermill":{"duration":0.00705,"end_time":"2023-01-20T20:37:18.790135","exception":false,"start_time":"2023-01-20T20:37:18.783085","status":"completed"},"tags":[]},"source":["Now, we will load the Scikit Learning implementation of Logistic Regression to compare with our implementation."]},{"cell_type":"markdown","id":"f3ee1cd5","metadata":{"papermill":{"duration":0.007176,"end_time":"2023-01-20T20:37:18.804712","exception":false,"start_time":"2023-01-20T20:37:18.797536","status":"completed"},"tags":[]},"source":["# Scikit Learning Implementation\n","\n","The Scikit Learn `linear_model.LogisticRegression()` class implements a regularized logistic regression. his implementation can fit binary, One-vs-Rest, or multinomial logistic regression."]},{"cell_type":"code","execution_count":10,"id":"c3e48783","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:18.821486Z","iopub.status.busy":"2023-01-20T20:37:18.82077Z","iopub.status.idle":"2023-01-20T20:37:19.884094Z","shell.execute_reply":"2023-01-20T20:37:19.882794Z"},"papermill":{"duration":1.074333,"end_time":"2023-01-20T20:37:19.886488","exception":false,"start_time":"2023-01-20T20:37:18.812155","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"markdown","id":"0816749d","metadata":{"papermill":{"duration":0.007061,"end_time":"2023-01-20T20:37:19.901298","exception":false,"start_time":"2023-01-20T20:37:19.894237","status":"completed"},"tags":[]},"source":["Let's us import a data set to make predictions. As an example we will use a data set from National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of  these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."]},{"cell_type":"code","execution_count":11,"id":"02dbb0a7","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:19.917944Z","iopub.status.busy":"2023-01-20T20:37:19.917562Z","iopub.status.idle":"2023-01-20T20:37:19.944004Z","shell.execute_reply":"2023-01-20T20:37:19.94243Z"},"papermill":{"duration":0.038091,"end_time":"2023-01-20T20:37:19.946787","exception":false,"start_time":"2023-01-20T20:37:19.908696","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n","0            6      148             72             35        0  33.6   \n","1            1       85             66             29        0  26.6   \n","2            8      183             64              0        0  23.3   \n","3            1       89             66             23       94  28.1   \n","4            0      137             40             35      168  43.1   \n","\n","   DiabetesPedigreeFunction  Age  Outcome  \n","0                     0.627   50        1  \n","1                     0.351   31        0  \n","2                     0.672   32        1  \n","3                     0.167   21        0  \n","4                     2.288   33        1  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","diabetes_df = pd.read_csv('/kaggle/input/diabetes-dataset/diabetes.csv')\n","diabetes_df.head()"]},{"cell_type":"markdown","id":"53daf938","metadata":{"papermill":{"duration":0.007313,"end_time":"2023-01-20T20:37:19.961953","exception":false,"start_time":"2023-01-20T20:37:19.95464","status":"completed"},"tags":[]},"source":["The outcome collumn dysplay 1 for a positive diabetes diagnostic and 0 for negative. \n","\n","Now, we will remove this columns and split the data in a train and test data frames."]},{"cell_type":"code","execution_count":12,"id":"dbea7afe","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:19.979007Z","iopub.status.busy":"2023-01-20T20:37:19.978629Z","iopub.status.idle":"2023-01-20T20:37:20.00277Z","shell.execute_reply":"2023-01-20T20:37:20.000972Z"},"papermill":{"duration":0.035433,"end_time":"2023-01-20T20:37:20.005103","exception":false,"start_time":"2023-01-20T20:37:19.96967","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 768 entries, 0 to 767\n","Data columns (total 9 columns):\n"," #   Column                    Non-Null Count  Dtype  \n","---  ------                    --------------  -----  \n"," 0   Pregnancies               768 non-null    int64  \n"," 1   Glucose                   768 non-null    int64  \n"," 2   BloodPressure             768 non-null    int64  \n"," 3   SkinThickness             768 non-null    int64  \n"," 4   Insulin                   768 non-null    int64  \n"," 5   BMI                       768 non-null    float64\n"," 6   DiabetesPedigreeFunction  768 non-null    float64\n"," 7   Age                       768 non-null    int64  \n"," 8   Outcome                   768 non-null    int64  \n","dtypes: float64(2), int64(7)\n","memory usage: 54.1 KB\n"]}],"source":["diabetes_df.info()"]},{"cell_type":"code","execution_count":13,"id":"0768e86f","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.022204Z","iopub.status.busy":"2023-01-20T20:37:20.021761Z","iopub.status.idle":"2023-01-20T20:37:20.032412Z","shell.execute_reply":"2023-01-20T20:37:20.031415Z"},"papermill":{"duration":0.02246,"end_time":"2023-01-20T20:37:20.035263","exception":false,"start_time":"2023-01-20T20:37:20.012803","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","y = diabetes_df['Outcome']\n","X = diabetes_df.drop(axis=1, columns='Outcome')\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.5)"]},{"cell_type":"markdown","id":"2f1b4870","metadata":{"papermill":{"duration":0.007291,"end_time":"2023-01-20T20:37:20.050443","exception":false,"start_time":"2023-01-20T20:37:20.043152","status":"completed"},"tags":[]},"source":["### Fit the Model"]},{"cell_type":"code","execution_count":14,"id":"f397f894","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.067614Z","iopub.status.busy":"2023-01-20T20:37:20.067239Z","iopub.status.idle":"2023-01-20T20:37:20.109209Z","shell.execute_reply":"2023-01-20T20:37:20.107723Z"},"papermill":{"duration":0.053654,"end_time":"2023-01-20T20:37:20.111759","exception":false,"start_time":"2023-01-20T20:37:20.058105","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["LogisticRegression(max_iter=150, random_state=1)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Defining our logistic regression model fixing a random state (to do always the same predictions) and the number of iterations \n","sk_model = LogisticRegression(random_state=1, max_iter=150)\n","# Training our model\n","sk_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":15,"id":"c23a7c5e","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.130555Z","iopub.status.busy":"2023-01-20T20:37:20.129041Z","iopub.status.idle":"2023-01-20T20:37:20.137075Z","shell.execute_reply":"2023-01-20T20:37:20.135608Z"},"papermill":{"duration":0.019683,"end_time":"2023-01-20T20:37:20.13952","exception":false,"start_time":"2023-01-20T20:37:20.119837","status":"completed"},"tags":[]},"outputs":[],"source":["# Making predictions\n","sk_predictions = sk_model.predict(X_test)"]},{"cell_type":"markdown","id":"9ce8ec5a","metadata":{"papermill":{"duration":0.007342,"end_time":"2023-01-20T20:37:20.154853","exception":false,"start_time":"2023-01-20T20:37:20.147511","status":"completed"},"tags":[]},"source":["# Comparing Scikit Learning predictions with the real diagnostic:"]},{"cell_type":"code","execution_count":16,"id":"e242036d","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.172552Z","iopub.status.busy":"2023-01-20T20:37:20.171665Z","iopub.status.idle":"2023-01-20T20:37:20.176121Z","shell.execute_reply":"2023-01-20T20:37:20.175344Z"},"papermill":{"duration":0.015309,"end_time":"2023-01-20T20:37:20.17796","exception":false,"start_time":"2023-01-20T20:37:20.162651","status":"completed"},"tags":[]},"outputs":[],"source":["# Importing a metric\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":17,"id":"3ef28cd4","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.195635Z","iopub.status.busy":"2023-01-20T20:37:20.194947Z","iopub.status.idle":"2023-01-20T20:37:20.202593Z","shell.execute_reply":"2023-01-20T20:37:20.201139Z"},"papermill":{"duration":0.019332,"end_time":"2023-01-20T20:37:20.205052","exception":false,"start_time":"2023-01-20T20:37:20.18572","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0.7708333333333334"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["sk_score = accuracy_score(y_test, sk_predictions)\n","sk_score"]},{"cell_type":"markdown","id":"48ac6874","metadata":{"papermill":{"duration":0.007347,"end_time":"2023-01-20T20:37:20.220552","exception":false,"start_time":"2023-01-20T20:37:20.213205","status":"completed"},"tags":[]},"source":["This means that the Scikit Learning logistic model with the parameters choice above hit the predictions nearly $77\\%$ of the time, for the Diabets dataset. Its not so good having $23\\%$ of a population being incorrectly diagnosed, but its important to note that this is a simple example, to improve this score one can vary some parameters of the Logistic Regression class and fetch for correlation between the dependent variables. "]},{"cell_type":"markdown","id":"2bfbc5ec","metadata":{"papermill":{"duration":0.00746,"end_time":"2023-01-20T20:37:20.23667","exception":false,"start_time":"2023-01-20T20:37:20.22921","status":"completed"},"tags":[]},"source":["# Comparing our Logistic Model with the Scikit Learning Class "]},{"cell_type":"code","execution_count":18,"id":"1aa8d74b","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.255269Z","iopub.status.busy":"2023-01-20T20:37:20.254339Z","iopub.status.idle":"2023-01-20T20:37:20.27264Z","shell.execute_reply":"2023-01-20T20:37:20.271531Z"},"papermill":{"duration":0.030233,"end_time":"2023-01-20T20:37:20.275178","exception":false,"start_time":"2023-01-20T20:37:20.244945","status":"completed"},"tags":[]},"outputs":[],"source":["my_pred = my_Logistic_Regression(X_train, y_train, X_test, learning_rate=0.000005, n_iterations=9)"]},{"cell_type":"code","execution_count":19,"id":"eaeae4e5","metadata":{"execution":{"iopub.execute_input":"2023-01-20T20:37:20.292154Z","iopub.status.busy":"2023-01-20T20:37:20.291745Z","iopub.status.idle":"2023-01-20T20:37:20.298535Z","shell.execute_reply":"2023-01-20T20:37:20.297801Z"},"papermill":{"duration":0.017765,"end_time":"2023-01-20T20:37:20.300694","exception":false,"start_time":"2023-01-20T20:37:20.282929","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0.640625"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(y_test, my_pred)"]},{"cell_type":"markdown","id":"e7e25065","metadata":{"papermill":{"duration":0.007907,"end_time":"2023-01-20T20:37:20.316747","exception":false,"start_time":"2023-01-20T20:37:20.30884","status":"completed"},"tags":[]},"source":["For this particular case our implementation scored relatively well compared to the Scikit Learning class."]},{"cell_type":"markdown","id":"1b6533fe","metadata":{"papermill":{"duration":0.007455,"end_time":"2023-01-20T20:37:20.3325","exception":false,"start_time":"2023-01-20T20:37:20.325045","status":"completed"},"tags":[]},"source":["It is important to mention that the model is extremely sentitive to the learning rate. The particular values of the 'x' features are pratically not affected by a learning rate greater than 0.000005."]},{"cell_type":"markdown","id":"9fe1fe6d","metadata":{"papermill":{"duration":0.007269,"end_time":"2023-01-20T20:37:20.347365","exception":false,"start_time":"2023-01-20T20:37:20.340096","status":"completed"},"tags":[]},"source":["# References\n","\n","* [Logistic Regression - Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression#Definition)\n","* [Logistic Regression — Detailed Overview](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)\n","* [Logistic Regression Implementation](https://www.kaggle.com/code/kanncaa1/logistic-regression-implementation)"]},{"cell_type":"code","execution_count":null,"id":"ac254003","metadata":{"papermill":{"duration":0.007323,"end_time":"2023-01-20T20:37:20.362486","exception":false,"start_time":"2023-01-20T20:37:20.355163","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":10.335005,"end_time":"2023-01-20T20:37:21.092397","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-01-20T20:37:10.757392","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}